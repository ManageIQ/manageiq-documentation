[[Capacity_Planning]]
== Capacity Planning

[[capacity-and-utilization-collection]]
=== Capacity and Utilization Collection

{product-title} server can collect and analyze capacity and
utilization data from your virtual infrastructure. Use this data to
understand the limitations of your current environment and plan for
growth.

For some capacity and utilization data, {product-title}
calculates and shows trend lines in the charts. Trend lines are created using linear regression, which is calculated using the capacity and utilization data collected by {product-title} during the interval you specify for the chart. The more data you have the better the
predictive value of the trend line.

There are three server roles associated with the collection and metric
creation of capacity and utilization.

* The Capacity & Utilization Coordinator role checks to see if it is
  time to collect data, somewhat like a scheduler. If it is time, a job
  is queued for the capacity and utilization data collector. The
  coordinator role is required to complete capacity and utilization
  data collection. If more than one Server in a specific zone has this
  role, only one will be active at a time.

* The Capacity & Utilization Data Collector performs the actual
  collection of capacity and utilization data. This role has a
  dedicated worker, and there can be more than one server with this
  role in a zone.

* The Capacity & Utilization Data Processor processes all of the data
  collected, allowing {product-title} to create charts.
  This role has a dedicated worker, and there can be more than one
  server with this role in a zone.

[[assigning_the_capacity_and_utilization_server_roles]]
=== Assigning the Capacity and Utilization Server Roles

include::common/cap-util-assign-server-roles.adoc[]

[NOTE]
====
In addition to setting the server role, you must also select which clusters and datastores to collect data for. For more information, see General Configuration. You must have super administrator rights to edit these settings.
====

[[data_collection_for_rhev_33_34]]
=== Data Collection for Red Hat Enterprise Virtualization 3.3 and 3.4

To collect capacity and utilization data for Red Hat Enterprise
Virtualization 3.3 and 3.4, you must add {product-title} as
a user to the RHEV-M database.

Perform this procedure on the PostgreSQL server where the history
database is located. Usually, this is the RHEV-M server.

. Using SSH, access the RHEV-M database server as the root user:
+
------
$ ssh root@example.postgres.server
------
+
. Switch to the postgres user:
+
------
# su - postgres
------
+
. Access the database prompt:
+
------
-bash-4.1$ psql
------
+
. Create a new user for the {product-title}:
+
------
postgres=# CREATE ROLE cfme LOGIN UNENCRYPTED PASSWORD 'smartvm' SUPERUSER VALID UNTIL 'infinity';
------
+
. Exit to the RHEV-M database server prompt:
+
------
postgres=# \q
-bash-4.1$ exit
------
+
. Update the server's firewall to accept TCP communication on port
  5432:
+
------
# iptables -I INPUT -p tcp -m tcp --dport 5432 -j ACCEPT
# service iptables save
------
+
. Enable external md5 authentication by appending the following line to
  `/var/lib/pgsql/data/pg_hba.conf`:
+
------
host    all      all    0.0.0.0/0     md5
------
+
. Enable PostgreSQL to listen for remote connections by updating the
  `listen_addresses` line in `/var/lib/pgsql/data/postgresql.conf`:
+
------
listen_addresses  =  '*'
------
+
. Reload the PostgreSQL configuration:
+
------
service postgresql reload
------
+


[[adding-database-credentials-for-data-collection]]
=== Adding Database Credentials for Data Collection

After creating the new user, add the user's credentials to the settings for the provider.

. From menu:Compute[Infrastructure > Providers], select an infrastructure provider to update its settings.
. Click image:1847.png[]*Configuration*, and then image:1851.png[]*Edit Selected Infrastructure Provider*.
. In the *Credentials* area, click *C & U Database*.
. Type in the credentials for the new database user you created.
. Click *Save*.
. Restart the capacity and utilization data collector.

[[data_collection_for_osp]]
=== Data Collection for Red Hat Enterprise Linux OpenStack Platform

Before you can collect data from a Red Hat Enterprise Linux OpenStack
Platform (RHEL-OSP) provider, you must install Ceilometer and configure it
to accept queries from external systems.

These instructions require a Red Hat Enterprise Linux 6.4 @base
installation of RHEL-OSP and registration to a satellite that has access
to both the `RHEL-OSP` and `RHEL Server Optional` channels. Perform all steps on your RHEL-OSP system.

. Add the required channels and update your system:
+
------
# rhn-channel --add -c rhel-x86_64-server-6-ost-3 -c rhel-x86_64-server-optional-6
# yum update -y
# reboot
------
+
. Install `Ceilometer`:
+
------
# yum install *ceilometer*
------
+
. Install and start the MongoDB store:
+
------
# yum install mongodb-server
# sed -i '/--smallfiles/!s/OPTIONS=\"/OPTIONS=\"--smallfiles /' /etc/sysconfig/mongod
# service mongod start
------
+
. Create the following users and roles:
+
------
# SERVICE_TENANT=$(keystone tenant-list | grep services | awk '{print $2}')
# ADMIN_ROLE=$(keystone role-list | grep ' admin ' | awk '{print $2}')
# SERVICE_PASSWORD=servicepass
# CEILOMETER_USER=$(keystone user-create --name=ceilometer \
--pass="$SERVICE_PASSWORD" \
--tenant_id $SERVICE_TENANT \
--email=ceilometer@example.com | awk '/ id / {print $4}')
# RESELLER_ROLE=$(keystone role-create --name=ResellerAdmin | awk '/ id / {print $4}')
# ADMIN_ROLE=$(keystone role-list | awk '/ admin / {print $2}')
# for role in $RESELLER_ROLE $ADMIN_ROLE ; do
keystone user-role-add --tenant_id $SERVICE_TENANT \
--user_id $CEILOMETER_USER --role_id $role
done
------
+
. Configure the authtoken in `ceilometer.conf`:
+
------
# openstack-config --set /etc/ceilometer/ceilometer.conf keystone_authtoken auth_host 127.0.0.1
# openstack-config --set /etc/ceilometer/ceilometer.conf keystone_authtoken auth_port 35357
# openstack-config --set /etc/ceilometer/ceilometer.conf keystone_authtoken auth_protocol http
# openstack-config --set /etc/ceilometer/ceilometer.conf keystone_authtoken admin_tenant_name services
# openstack-config --set /etc/ceilometer/ceilometer.conf keystone_authtoken admin_user ceilometer
# openstack-config --set /etc/ceilometer/ceilometer.conf keystone_authtoken admin_password $SERVICE_PASSWORD
------
+
. Configure the user credentials in `ceilometer.conf`:
+
------
# openstack-config --set /etc/ceilometer/ceilometer.conf DEFAULT os_auth_url http://127.0.0.1:35357/v2.0
# openstack-config --set /etc/ceilometer/ceilometer.conf DEFAULT os_tenant_name services
# openstack-config --set /etc/ceilometer/ceilometer.conf DEFAULT os_password $SERVICE_PASSWORD
# openstack-config --set /etc/ceilometer/ceilometer.conf DEFAULT os_username ceilometer
------
+
. Start the Ceilometer services:
+
------
# for svc in compute central collector api ; do
  service openstack-ceilometer-$svc start
  done
------
+
. Register an endpoint with the service catalog. Replace `$EXTERNALIFACE`
  with the IP address of your external interface:
+
------
# keystone service-create --name=ceilometer \
--type=metering --description="Ceilometer Service"
# CEILOMETER_SERVICE=$(keystone service-list | awk '/ceilometer/ {print $2}')
# keystone endpoint-create \
--region RegionOne \
--service_id $CEILOMETER_SERVICE \
--publicurl "http://$EXTERNALIFACE:8777/" \
--adminurl "http://$EXTERNALIFACE:8777/" \
--internalurl "http://localhost:8777/"
------
+
. Enable access to Ceilometer from external systems:
+
------
# iptables -I INPUT -p tcp -m multiport --dports 8777 -m comment --comment "001 ceilometer incoming" -j ACCEPT
# iptables save
------
+
. Confirm the status of OpenStack and the Ceilometer services:
+
------
# openstack-status
# for svc in compute central collector api ; do
  service openstack-ceilometer-$svc status
  done
------
+
. Verify Ceilometer is working correctly by authenticating as a user
  with instances running, for example `admin`. Pipe the sample for the
  CPU meter to count lines, and confirm that the value changes according
  to the interval specified in `/etc/ceilometer/pipeline.yaml`. The
  default interval is 600 seconds.
+
------
# . ~/keystonerc_admin
# ceilometer sample-list -m cpu |wc -l
------
+
. Add the configured OpenStack provider to {product-title}. See
ifdef::cfme[link:https://access.redhat.com/documentation/en/red-hat-cloudforms/4.1/managing-providers/#adding_openstack_providers[Adding OpenStack Providers] in _Managing Providers_.]
ifdef::miq[Managing Providers]
  After adding the provider, capacity and utilization data for your instances
  populate in a few minutes.

[[data_collected]]
=== Data Collected

{product-title} generates charts from the collected data
which can be used to plan your hardware and virtual machine needs.
Depending on the type of data, these charts may include lines for
averages, maximums, minimums, and trends.


[NOTE]
====
For reporting of daily capacity and utilization data, incomplete days
(days with less than 24 hourly data points from midnight to midnight)
that are at the beginning or end of the requested interval are excluded.
Days with less than 24 hourly data points would be inaccurate and
including them would skew trend lines. Therefore, at least one full day
of hourly data from midnight to midnight is necessary for displaying the
capacity and utilization charts under the menu:Compute[Infrastructure] tab.
====

[[capacity-and-utilization-charts-for-host,-clusters,-and-virtual-machines]]
==== Capacity and Utilization Charts for Host, Clusters, and Virtual Machines

.Capacity and Utilization Charts for Host, Clusters, and Virtual Machines
[width="100%",cols="3,1,1,1,1,1,1,1",options="header",]
|=======================================================================
| Resource Type | CPU Usage | CPU States | Disk I/O | Memory Usage | Network I/O | Running VMS | Running Hosts
| Host          | Y         | Y          | Y        | Y            | Y           | Y           | NA
| Cluster       | Y         | Y          | Y        | Y            | Y           | Y           | Y
| Virtual Machine | Y       | Y          | Y        | Y            | Y           | NA          | NA
|=======================================================================

ifdef::cfme[]
For procedures to view capacity and utilization charts for hosts, clusters, and virtual machines, see the following sections in _Managing Infrastructure and Inventory_:

* link:https://access.redhat.com/documentation/en/red-hat-cloudforms/4.1/managing-infrastructure-and-inventory/#viewing_capacity_and_utilization_charts_for_a_host[Viewing Capacity and Utilization Charts for a Host]
* link:https://access.redhat.com/documentation/en/red-hat-cloudforms/4.1/managing-infrastructure-and-inventory/#viewing_capacity_and_utilization_charts_for_a_cluster[Viewing Capacity and Utilization Charts for a Cluster]
* link:https://access.redhat.com/documentation/en/red-hat-cloudforms/4.1/managing-infrastructure-and-inventory/#to_view_capacity_and_utilization_charts_for_a_virtual_machine[Viewing Capacity and Utilization Charts for a
Virtual Machine]
endif::cfme[]

[[capacity-and-utilization-charts-for-datastores]]
==== Capacity and Utilization Charts for Datastores

Charts created include:

.Capacity and Utilization Charts for Datastores
[width="100%",cols="50%,50%",options="header",]
|====
| Space by VM Type                      | Virtual Machines and Hosts
| Used Space                            | Number of VMs by Type
| Disk files Space                      | Hosts
| Snapshot Files Space                  | Virtual Machines
| Memory Files Space |
| Non-VM Files       |
| Used Disk Space    |
|====

ifdef::cfme[]
See link:https://access.redhat.com/documentation/en/red-hat-cloudforms/4.1/managing-infrastructure-and-inventory/[Viewing Capacity and Utilization Charts for a Datastore] in _Managing Infrastructure and Inventory_ for more information.
endif::cfme[]

[[chart-features]]
=== Chart Features

Each chart provides its own set of special features including zooming in
on a chart and shortcut menus.

[[zooming-into-a-chart]]
==== Zooming into a Chart

. Navigate to the chart you want to zoom. If you hover anywhere on the
  chart, two dashed lines will appear to target a coordinate of the
  chart.
. Click image:2251.png[](*Click to zoom in*) in the lower left corner of the
  chart to zoom into it.
. To go back to the regular view click image:2252.png[](*Click to zoom out*) on
  the enlarged chart.

[[drilling-into-chart-data]]
==== Drilling into Chart Data

. Navigate to the chart you want to get more detail from.
. Hover over a data point to see the coordinates.
. Click on a data point to open a shortcut menu for the chart. In this
  example, we can use the shortcut menu to go to the hourly chart or
  display the virtual machines that were running at the time the data
  was captured.
+
* If you are viewing the *CPU*, *Disk*, *Memory*, or *Network* charts,
  selecting from the *Chart* option will change all of the charts on
  the page to the new interval selected.
* If you are viewing the *CPU*, *Disk*, *Memory*, or *Network* charts,
  selecting from the *Display* option will allow you to drill into
  the virtual machines or *Hosts* that were running at the time.
* If you are viewing the *VM* or *Hosts* chart, the *Display* menu will
  allow you to view running or stopped virtual machines. The time
  of the data point will be displayed in addition to the virtual
  machines that apply. From here, click on a virtual machine to view
  its details.

[[optimization]]
=== Optimization

{product-title}'s optimization functions allow you to view
utilization trends, and identify and project bottlenecks in your
environment. In addition, you can predict where you have capacity for
additional virtual machines.

[NOTE]
====
For reporting of daily optimization data, incomplete days (days with less
than 24 hourly data points from midnight to midnight) that are at the
beginning or end of the requested interval are excluded. Days with less
than 24 hourly data points would be inaccurate and including them would
skew trend lines. Therefore, the *Optimize* page requires at least two full
days of daily data because all the charted values are derived from trend
calculations and that requires at least two data points
====

[[utilization-trends]]
=== Utilization Trends

{product-title} allows you to view the resource utilization
of your clusters, providers, and datastores. You can choose from summary,
details, or report view.

[[viewing-utilization-trend-summary]]
==== Viewing Utilization Trend Summary

This procedure shows you how to view utilization trend summary.

. Navigate to menu:Optimize[Utilization].
. Click *Summary* if it is not already selected.
. Expand the tree on the left side, until you can see the desired
  providers, clusters, or datastores.
. Click on the item.
. Use the *Options* section in the *Summary* tab to change the
  characteristics of the data.
+
* Use *Trends* to select how far back you want to calculate
  the trend.
* Use *Selected Day* for the date you want to see percent utilization
  for in the chart on the *Summary* tab.
* Use *Classification* to only see trends for a specific applied tag.
* Use *Time Profile* to select an existing time profile. If the
  logged on user does not have any time profiles available, this
  option will not show.
* Select a *Time Zone*.

[[viewing-detail-lines-of-a-utilization-trend]]
==== Viewing Detail Lines of a Utilization Trend

This procedure shows you how to view detail lines of a utilization trend.

. Navigate to menu:Optimize[Utilization].
. Expand the tree on the left side, until you can see the desired
  providers, clusters, or datastores.
. Click on the item.
. Click *Details* if it is not already selected.
. From the *Options* area, select how far back you want to view the
  trends for and any classifications you want to use.

[[viewing-a-report-of-a-utilization-trend]]
==== Viewing a Report of a Utilization Trend

To find out more about resource utilization, view utilization trend
reports.

. Navigate to menu:Optimize[Utilization].
. Expand the tree on the left side, until you can see the desired
  providers, clusters, or datastores.
. Click on the item.
. Click *Report* if it is not already selected.
. From the *Options* area, select how far back you want to view the
  trends for and any classifications you want to use.

[[planning-where-to-put-a-new-virtual-machine]]
=== Planning Where to Put a New Virtual Machine

You can use the data collected in the VMDB to plan where you can put 
additional virtual machines. {product-title} allows you to
use a reference virtual machine as an example to plan on which hosts and 
clusters you can place a new virtual machine.

. Navigate to menu:Optimize[Planning].
. From *Reference VM Selection*, use the dropdowns to select the virtual
  machine that is most like the one that you want to add.
+
image:2254.png[]
+
. Select the required *VM Options* for what you want to base the
  calculations on.
+
image:2255.png[]
+
From the *Source* list, select the type of data to use as the
source for your projections. For example, select *Allocation* to
calculate based on the current allocation values of each resource
(CPU, memory, or disk space) for the reference virtual machine. Use
*Reservation* to project based on the current guaranteed
value of the specific resource (CPU Speed, CPU count, memory, or disk
space) although that amount may not be allocated to the virtual
machine at a specific moment in time. Select *Usage* if you want to
calculate based on usage history of the reference virtual machine.
Use *Manual Input* to enter your own set of parameters for each
resource.
+
. From *Target Options / Limits*, select if you want to use clusters or hosts as your targets.
+
image:2256.png[]
+
Also, select the limit of how high the projection can go for CPU,
memory, and datastore space. If you are targeting hosts, you will be
able to select a filter for which hosts can be targets.
+
. From *Trend Options*, select how far back you want to use the trend
  data for, a *Time Profile* and *Time Zone* if applicable. Note that *Time
  Profile* will only show if the logged on user has a *Time Profile*
  available.
. Click *Submit*.

The *Summary* tab shows the best clusters or hosts on which to
place the virtual machines. The *Report* tab shows the best fit and
statistics on the reference virtual machine in a tabular format. From the
*Report* tab, you can also create a PDF of the report or download the data
in `txt` or `csv` format.


[[bottlenecks]]
=== Bottlenecks

{product-title} can show where bottlenecks occur in your
virtual infrastructure. You can view them either on a timeline or as a
report which can be downloaded for further analysis. 

[[prerequisites]]
==== Prerequisites

* Bottleneck reports use the same mechanism to gather data as Capacity and Utilization reports. To enable data collection in {product-title}, see the following sections:
** xref:assigning_the_capacity_and_utilization_server_roles[]
** xref:data_collected[]
* Additionally, configure your {product-title} for collecting capacity and utilization reports for clusters and datastores by following this procedure:
.. Navigate to menu:Settings[Configuration]. 
.. Select *Region* from the *Settings* tab in the left pane of the appliance. 
.. In the right pane, under the *C & U Collection* tab, check the boxes for *Collect for All Clusters* under *Clusters* and *Collect for All Datastores* under *Datastores*, or check the boxes for the clusters/datastores you desire.
+
[NOTE]
====
*Collect for All Clusters* must be checked to be able to collect capacity and utilization data from cloud providers such as Red Hat OpenStack or Amazon EC2.
====
+
.. Click *Save*.
* For bottleneck reports to work as expected, the data collection for Capacity and Utilization reports should also be enabled for the relevant backend provider. See the following documentation to enable data collection for Red Hat Enterprise Virtualization and Red Hat Enterprise Linux OpenStack Platform provider:
** For Red Hat Enterprise Virtualization: xref:data_collection_for_rhev_33_34[]
** For Red Hat Enterprise Linux OpenStack Platform: xref:data_collection_for_osp[]

[NOTE]
====
For reporting of daily bottleneck data, incomplete days
(days with less than 24 hourly data points from midnight to midnight)
that are at the beginning or end of the requested interval are excluded.
Days with less than 24 hourly data points would be inaccurate and
including them would skew trend lines. Therefore, at least one full day
of hourly data from midnight to midnight is necessary for displaying the
bottleneck charts under the *Optimize* tab.
====

[[viewing-the-bottleneck-summary]]
==== Viewing the Bottleneck Summary
To find out more about bottleneck capacity or utilization, view a
bottleneck summary.

. Navigate to menu:Optimize[Bottlenecks].
. Click *Summary* if it is not already selected.
. Expand the tree on the left side, until you can see the desired
  providers, clusters, or datastores.
. Click on the item.
. Use the *Options* section to change the characteristics of the data.
  image:2257.png[]
+
* Use *Event Groups* to select if you want to see bottlenecks based
  on capacity, utilization or both.
* Select a *Time Zone*.
+

Data is processed, and a timeline appears. Click on an icon in
the timeline to see specific information on the bottleneck.

[[viewing-a-report-of-the-bottlenecks-trend]]
==== Viewing a Report of the Bottlenecks Trend

. Navigate to menu:Optimize[Bottlenecks].
. Click *Report*.
. Expand the tree on the left side, until you can see the desired
  providers, clusters, or datastores.
. Click on the item.
. Use the *Options* section to change the characteristics of the data.
  image:2258.png[]
+
* Use *Event Groups* to select if you want to see bottlenecks based
  on capacity, utilization or both.
* Select a *Time Zone*.
+
. Expand the tree on the left side, until you can see the enterprise,
  provider, or datastore that you want to see the trend for.








